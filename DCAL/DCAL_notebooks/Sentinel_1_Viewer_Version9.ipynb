{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style= \"color:red; font-size:30px\">\n",
    "<b>Sentinel-1 Data Analysis Notebook</b>\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"import\">Import Dependencies and Connect to the Data Cube [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Ignore warnings (from NDVI)\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "# Set a legible font size for matplotlib plots.\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# Import the datacube and the API\n",
    "import datacube\n",
    "import sys\n",
    "import pandas as pd\n",
    "from odc.ui import DcViewer\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "from xarray.ufuncs import fabs\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from xarray.ufuncs import isfinite\n",
    "\n",
    "#import DE Africa script\n",
    "sys.path.append('../../Scripts')\n",
    "from deafrica_plotting import display_map\n",
    "\n",
    "import matplotlib\n",
    "sys.path.append('../DCAL_utils')\n",
    "from dc_time import _n64_to_datetime\n",
    "from plotter_utils import month_names_long\n",
    "from plotter_utils import figure_ratio, retrieve_or_create_fig_ax\n",
    "from plotter_utils import xarray_time_series_plot\n",
    "from plotter_utils import intersection_threshold_plot\n",
    "from dc_rgb import rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"S1_viewer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Sentinel-1 product measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aliases</th>\n",
       "      <th>dtype</th>\n",
       "      <th>flags_definition</th>\n",
       "      <th>name</th>\n",
       "      <th>nodata</th>\n",
       "      <th>units</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measurement</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vh</th>\n",
       "      <td>[VH]</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vv</th>\n",
       "      <td>[VV]</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            aliases    dtype flags_definition name nodata units\n",
       "measurement                                                    \n",
       "vh             [VH]  float32              NaN   vh    NaN     1\n",
       "vv             [VV]  float32              NaN   vv    NaN     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"sentinel1_ghana_monthly\"\n",
    "\n",
    "measurements = dc.list_measurements()\n",
    "measurements.loc[product]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"extents\">View the Extent of Data Avalibility in the Cube [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the year specified below to view data avalibility for different years\n",
    "\n",
    "There's a limit of 500 datasets for the extents to display. \n",
    "If more than 500 datasets are found for a time period, click \"show\" on upper-right corner to force display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d8c32d2c964b619b2945286825e78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(layout=Layout(flex='0 1 auto', width='10em'), options=('sentinel1_ghanaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DcViewer(dc=dc,\n",
    "         products=[product],\n",
    "         time='2018',\n",
    "         center=(7.5, 0),\n",
    "         zoom=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"define_extents\">Define the Extents of the Analysis [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify latitude and longitude bounds of an interesting area within the full extents.\n",
    "# shown in the metadata report above (reduce area for faster processing times).\n",
    "\n",
    "# Mining in Kibi, Ghana (N6.16789 W0.54533) \n",
    "# increased vegetation from Jan 2017 to Dec 2018\n",
    "# lat = (6.166, 6.175)\n",
    "# lon = (-0.548, -0.539)\n",
    "\n",
    "## Mining in Asikam, Ghana (N6.20339 W0.53754)\n",
    "# lat = (6.190, 6.209) \n",
    "# lon = (-0.548, -0.530)\n",
    "\n",
    "# Mining region west of Obuasi, Ghana\n",
    "lat = (6.2286, 6.2822)\n",
    "lon = (-1.9324, -1.8871)\n",
    "\n",
    "# Water Demo for Mining\n",
    "# lat = (6.2407, 6.2444)\n",
    "# lon = (-1.9025, -1.8993)\n",
    "\n",
    "# Mining Area - Deforestation Example\n",
    "# lat = (6.2485, 6.2575)\n",
    "# lon = (-1.8908, -1.8808)\n",
    "\n",
    "# Kumasi City (large region)\n",
    "#lat = (6.5719, 6.8420 )\n",
    "#lon = (-1.7538, -1.4558)\n",
    "\n",
    "# Barekese Dam\n",
    "# lat = (6.8201, 6.8688)\n",
    "# lon = (-1.7476, -1.6780)\n",
    "\n",
    "# Okosombo - Volta River (diverse region)\n",
    "# lat = (6.2546, 6.3226)\n",
    "# lon = (0.0271, 0.0975)\n",
    "\n",
    "# Volta Region Mangroves\n",
    "#lat = (5.7666, 5.9425)\n",
    "#lon = (0.5546, 0.8175)\n",
    "\n",
    "# Densu Delta Ramsar Site\n",
    "#lat = (5.505, 5.572)\n",
    "#lon = (-0.330, -0.268)\n",
    "\n",
    "# Nyankpala agricultural area near Tamale, Ghana\n",
    "# Large seasonal variation in backscatter (>6dB) \n",
    "# lat = (9.35, 9.45)\n",
    "# lon = (-1.05, -0.95)\n",
    "\n",
    "# Central Ghana near Obuasi\n",
    "# lat = (6.00, 6.13)\n",
    "# lon = (-2.03, -1.86)\n",
    "\n",
    "# Time Period\n",
    "# Sentinel-1 data for Ghana is monthly and has a date tag of the 15th day in each month\n",
    "time_extents = ('2015-03-01', '2018-11-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the selected area**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7ff19a99c748>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_map(x=lon, y=lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"load_data\">Load Data from the Data Cube [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "sar_dataset = dc.load(product=product,\n",
    "                 x=lon,\n",
    "                 y=lat,\n",
    "                 time=time_extents)\n",
    "\n",
    "print(sar_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speckle filtering (optional)\n",
    "Note that this can take a while. Remove the comments to run this code.\n",
    "<br>The filter size refers to the number of pixels used in averaging window.\n",
    "<br> Filter sizes should be odd, such as 3 (for 3x3), 5, 7, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from raster_filter import stats_filter_2d\n",
    "\n",
    "#for time in sar_dataset.time:\n",
    "#      for data_var in sar_dataset:\n",
    "#         data_arr = sar_dataset.sel(time=time)[data_var]\n",
    "#         data_arr.values[:] = stats_filter_2d(data_arr, 'mean', filter_size=3).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a new band (VV/VH = vvvh) for histogram evaluation\n",
    "sar_dataset['vvvh'] = sar_dataset.vv / sar_dataset.vh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sar_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"visualize\">Visualize Data [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_threshold(ds, band_name, bottom = None , top = None, log_scaled = False, \n",
    "                   cmap_name = 'Greys', fig=None, ax=None):\n",
    "    # Threshold is applied to original data, not log scaled data(if you haven't scaled already)\n",
    "    _range = \"Full {} range: {}-{}\".format(band_name, ds[band_name].min().values,ds[band_name].max().values)\n",
    "\n",
    "    selection = ds[band_name]\n",
    "    \n",
    "    my_cmap = matplotlib.cm.get_cmap(cmap_name)\n",
    "    my_cmap.set_over('r')\n",
    "    my_cmap.set_under('b')\n",
    "    \n",
    "    fig, ax = retrieve_or_create_fig_ax(fig, ax)\n",
    "    \n",
    "    selection = 10*np.log10(selection) if log_scaled == True else selection\n",
    "    \n",
    "    bottom    = 10*np.log10(bottom)    if log_scaled == True and bottom is not None else bottom\n",
    "    top       = 10*np.log10(top)       if log_scaled == True and top is not None else top\n",
    "    \n",
    "    selection.plot(cmap = my_cmap, vmax =top, vmin = bottom, ax=ax)    \n",
    "    xlim, ylim = ax.set_xlim(), ax.set_ylim()\n",
    "    ax.text(min(xlim) + 0.5 * (max(xlim) - min(xlim)),\n",
    "            min(ylim) + -0.1 * (max(ylim) - min(ylim)),_range, horizontalalignment = \"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n64_to_month_and_year(n64):\n",
    "    datetime_val = _n64_to_datetime(n64)\n",
    "    return month_names_long[datetime_val.month-1] + ' ' + str(datetime_val.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show acquisition indices and times.\n",
    "print(\"Available acquisition indices and times\")\n",
    "times = sar_dataset.time.values\n",
    "months = np.array(list(map(n64_to_month_and_year, times)))\n",
    "pd.DataFrame(dict(times=times, months=months))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style= \"color:blue; font-size:25px\">\n",
    "<b>Single Date Analyses</b>\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a single acquisition by its index (listed above)\n",
    "acq_ind_to_show = 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine a range of values to limit the x axis to for histogram plots.\n",
    "# This allows the histograms to be more easily compared.\n",
    "# Use quantiles to avoid extreme outliers.\n",
    "\n",
    "# hist_ds = sar_dataset.isel(time=acq_ind_to_show)[['vv','vh','vvvh']]\n",
    "hist_ds = sar_dataset.isel(time=acq_ind_to_show)[['vv','vh']]\n",
    "hist_ds = hist_ds.where(isfinite(hist_ds))\n",
    "\n",
    "min_per_data_var = hist_ds.quantile(0.001).to_array().values\n",
    "min_val = min_per_data_var[np.isfinite(min_per_data_var)].min()\n",
    "\n",
    "max_per_data_var = hist_ds.quantile(0.999).to_array().values\n",
    "max_val = max_per_data_var[np.isfinite(max_per_data_var)].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "sar_dataset.isel(time=acq_ind_to_show).vv.plot.hist(ax=ax[0], bins=100, range=(-30,0), facecolor='green')\n",
    "sar_dataset.isel(time=acq_ind_to_show).vh.plot.hist(ax=ax[1], bins=100, range=(-30,0), facecolor='green')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling of backscatter amplitude for image outputs\n",
    "\n",
    "</b> Backscatter amplitude for each band can be scaled to an 8-bit range of 0-255 to improve visual output and maximize contrast in VV and VH image products. This process is explained here. Gamma-nought backscatter amplitude (in dB units) can be converted to raw (digital number) units using the conversion: DN (amplitude) = 10^(dB/20). Histograms are then used to view the range of dB values for the VV and VH bands. The range of expected values (across diverse land types) is then scaled to an 8-bit range using the formula: Scale = 256 / (range). Finally, an \"offset\" value is applied to allow the full range of values to be distributed across the 8-bit range. The final equation is: DN (amplitude, 8-bit) = ( DN(amplitude) - offset ) * scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sar_dataset['vv_amp_8b'] = (10**(sar_dataset.vv/20)-.1)*400\n",
    "sar_dataset['vh_amp_8b'] = (10**(sar_dataset.vh/20)-.06)*750\n",
    "sar_dataset['vvvh_amp_8b'] = (((10**(sar_dataset.vv/20)-.1)*400) / ((10**(sar_dataset.vh/20)-.06)*750)) * 100-25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGB images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled VV image\n",
    "rgb(sar_dataset.isel(time=acq_ind_to_show), \n",
    "    bands=['vv_amp_8b','vv_amp_8b','vv_amp_8b'], min_possible=0, max_possible=255, width=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled VH image\n",
    "rgb(sar_dataset.isel(time=acq_ind_to_show), \n",
    "    bands=['vh_amp_8b','vh_amp_8b','vh_amp_8b'], min_possible=0, max_possible=255, width=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled RGB (VV, VH, VV/VH)\n",
    "rgb(sar_dataset.isel(time=acq_ind_to_show), \n",
    "    bands=['vv_amp_8b','vh_amp_8b','vvvh_amp_8b'], min_possible = 0, max_possible = 255, width=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom RGB\n",
    "Select the image number and band for each RGB color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_rgb(dataset, rgb_to_data_arr_ind_map, **rgb_kwargs):\n",
    "    \"\"\"\n",
    "    Plots many images with a mapping of the red, green, and blue channels to data variables and\n",
    "    time indices in an `xarray.Dataset`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: xarray.Dataset\n",
    "        The dataset containing all data variables mentioned in `rgb_to_data_arr_ind_map`.\n",
    "        Must have a 'time' dimension.\n",
    "    rgb_to_data_arr_ind_map: list-like of list-like of int and string\n",
    "        A sequence of 3 sequences of 2 elements of time indices and data variables in `dataset` \n",
    "        to use as the red, green, and blue channels, respectively.\n",
    "        For example, [['nir', 0], ['swir1', 1], ['swir2', 2]] makes the red channel \n",
    "        the 'nir' data variable in time 0, the green channel the 'swir1' data variable in time 1, \n",
    "        and the green channel the 'swir2' data variable in time 2.\n",
    "    **rgb_kwargs: dict\n",
    "        Keyword arguments to pass to `utils.data_cube_utilities.dc_rgb.rgb()`.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fig, ax: matplotlib.figure.Figure, matplotlib.axes.Axes\n",
    "        The matplotlib figure and axes used to make the plot grid.\n",
    "    \"\"\"\n",
    "    # Obtain the data to plot.\n",
    "    rgb_data = {}\n",
    "    for channel, [data_var, time_ind] in zip(['red', 'green', 'blue'], rgb_to_data_arr_ind_map):\n",
    "        rgb_data[channel] = dataset[data_var].isel(time=time_ind)\n",
    "        rgb_data[channel] = rgb_data[channel].drop('time')\n",
    "    rgb_data = xr.Dataset(rgb_data)\n",
    "    rgb_kwargs['dataset'] = rgb_data\n",
    "    \n",
    "    rgb(**rgb_kwargs)\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom RGB logic\n",
    "# Select the band and scene index for each color, RGB, in order\n",
    "\n",
    "rgb_to_data_arr_ind_map = [['vh_amp_8b', 12], ['vh_amp_8b', 17], ['vh_amp_8b', 23]]\n",
    "custom_rgb(sar_dataset, rgb_to_data_arr_ind_map, min_possible=0, max_possible=255, width=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Date Threshold Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the single acquisition to use for threshold plot\n",
    "# Choose from the indices in the table above\n",
    "\n",
    "acq_ind_to_show = 11\n",
    "\n",
    "# Select the variable to plot: vv, vh, or vvvh\n",
    "\n",
    "threshold_data_var = 'vv'\n",
    "\n",
    "# Select the minimum and maximum values of the threshold range.\n",
    "# Below the low limit = BLUE\n",
    "# Above the high limit = RED\n",
    "\n",
    "threshold_range = (-12, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Threshold Plot Settings ##\n",
    "\n",
    "assert threshold_data_var in ['vv', 'vh', 'vvvh'], \\\n",
    "    \"The variable `threshold_data_var` must be one of 'vv', 'vh', or 'vvvh'.\"\n",
    "\n",
    "# Set the size of the figure.\n",
    "figsize = figure_ratio(sar_dataset.isel(time=acq_ind_to_show), fixed_width=10)\n",
    "## End Settings ##\n",
    "\n",
    "# acq_data = sar_dataset.isel(time=acq_ind_to_show)\n",
    "# if threshold_data_var == 'vvvh':\n",
    "#     acq_data['vvvh'] = acq_data.vv / acq_data.vh\n",
    "fig = plt.figure(figsize=figsize)\n",
    "bottom, top = threshold_range\n",
    "plot_threshold(sar_dataset.isel(time=acq_ind_to_show), \n",
    "               threshold_data_var, bottom=bottom, top=top, fig=fig)\n",
    "plt.title(str(sar_dataset.isel(time=acq_ind_to_show).time.values) + \n",
    "          \" - Threshold ({} < {} < {})\".format(bottom, threshold_data_var, top))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style= \"color:blue; font-size:25px\">\n",
    "<b>Time Series Analyses</b>\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box-and-Whisker and Gaussian Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the range of acquisitions to use for the time series plots\n",
    "# Choose from the indices in the table above\n",
    "# The lower bound is inclusive. The upper bound is exclusive\n",
    "\n",
    "acq_ind_ranges = [(0, 23)]\n",
    "\n",
    "# Select the variable to plot in the time series analyses\n",
    "# Choose vv, vh, or vvvh\n",
    "\n",
    "data_var_to_plot = 'vh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Settings #\n",
    "\n",
    "for i, acq_ind_range in enumerate(acq_ind_ranges):\n",
    "    assert acq_ind_range[0] >= 0 and acq_ind_range[1] > 0, \\\n",
    "        \"Indices in `acq_ind_ranges` must be positive (see index {}).\".format(i)\n",
    "    assert acq_ind_range[1] > acq_ind_range[0], \\\n",
    "        \"The second value in each pair of acquisition indices must be\" \\\n",
    "         \"greater than the first value (see index {}).\".format(i)\n",
    "\n",
    "assert data_var_to_plot in list(sar_dataset.data_vars.keys()), \\\n",
    "    \"The variable `data_var_to_plot` must be one of {}.\".format(list(sar_dataset.data_vars.keys()))\n",
    "\n",
    "# Select the binning approach for the vegetation index. Set the 'bin_by' parameter.\n",
    "# None          = do not bin the data\n",
    "# 'week'        = bin the data by week with an extended time axis\n",
    "# 'month'       = bin the data by month with an extended time axis\n",
    "# 'weekofyear'  = bin the data by week and years using a single year time axis\n",
    "# 'monthofyear' = bin the data by month and years using a single year time axis\n",
    "bin_by = 'week'\n",
    "assert bin_by in [None, 'week', 'month', 'weekofyear', 'monthofyear'], \\\n",
    "    \"The variable 'bin_by' can only have one of these values: \"\\\n",
    "    \"[None, 'week', 'month', 'weekofyear', 'monthofyear']\"\n",
    "\n",
    "# The maximum number of time slices for which data is plotted in a given plot grid cell.\n",
    "max_times_per_plot=50\n",
    "\n",
    "## End Settings ##\n",
    "\n",
    "# Format `acq_ind_ranges` for xarray `isel()` and select the acquisitions.\n",
    "acq_inds = np.concatenate([np.arange(*acq_ind_range) \n",
    "                           for acq_ind_range in acq_ind_ranges])\n",
    "plotting_data = sar_dataset.isel(time=acq_inds)\n",
    "\n",
    "aggregated_by_str = ''\n",
    "if bin_by is None:\n",
    "    plotting_data = plotting_data\n",
    "elif bin_by == 'week':\n",
    "    plotting_data = plotting_data.resample(time='1w').mean()\n",
    "    aggregated_by_str = 'By Week'\n",
    "elif bin_by == 'month':\n",
    "    plotting_data = plotting_data.resample(time='1m').mean()\n",
    "    aggregated_by_str = 'By Month'\n",
    "elif bin_by == 'weekofyear':\n",
    "    plotting_data = plotting_data.groupby('time.week').mean(dim=('time'))\n",
    "    aggregated_by_str = 'By Week of Year'\n",
    "elif bin_by == 'monthofyear':\n",
    "    plotting_data = plotting_data.groupby('time.month').mean(dim=('time'))\n",
    "    aggregated_by_str = 'By Month of Year'\n",
    "\n",
    "\n",
    "params = dict(dataset=plotting_data, \n",
    "              plot_descs={data_var_to_plot:{\n",
    "                  'none':[{'box':{'boxprops':{'facecolor':'forestgreen'}}}]}})\n",
    "\n",
    "xarray_time_series_plot(**params, fig_params=dict(figsize=(12,6), dpi=150), \n",
    "                        max_times_per_plot=max_times_per_plot)\n",
    "plt.title('Box-and-Whisker Plot of {} {} For Acquisition Index Ranges {} (inclusive, exclusive)'\n",
    "          .format(data_var_to_plot, aggregated_by_str, acq_ind_ranges))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_var_std_dev = plotting_data[data_var_to_plot].std().values\n",
    "params = dict(dataset=plotting_data, \n",
    "              plot_descs={data_var_to_plot:{\n",
    "                  'mean':[{'scatter':{}},\n",
    "                          {'gaussian_filter':{'sigma': (1/4)*data_var_std_dev}}]}})\n",
    "xarray_time_series_plot(**params, fig_params=dict(figsize=(12,6), dpi=150), \n",
    "                        max_times_per_plot=max_times_per_plot)\n",
    "plt.title('Gaussian Filter Fit of Mean of {} {} For Acquisition Index Ranges {} ' \n",
    "          '(inclusive, exclusive)'.format(data_var_to_plot, aggregated_by_str, acq_ind_ranges))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Statistics Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_filter(dataarray, statistic, filter_shape=(1,1)):\n",
    "    \"\"\"\n",
    "    Returns a mean, median, or standard deviation filter of an `xarray.DataArray`.\n",
    "    This function is more accurate than using SciPy or scikit-image methods, because\n",
    "    those don't handle the extremities ideally. Specifically, only values actually \n",
    "    inside the filter should be considered, so the data is padded with NaNs.\n",
    "    This function is resilient to NaNs in the data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataarray: xarray.DataArray\n",
    "        The data to create a filtered version of. Must have 3 dimensions, with\n",
    "        the last being 'time'.\n",
    "    statistic: string\n",
    "        The name of the statistic to use for the filter.\n",
    "        The possible values are ['mean', 'median', 'std'].\n",
    "    filter_shape: list-like of 2 odd, positive integers\n",
    "        The shape of the filter to use. Both dimensions should have odd lengths.\n",
    "    \"\"\"\n",
    "    filter_dims = dataarray.dims[:2]\n",
    "    filter_coords = {dim: dataarray.coords[dim] for dim in filter_dims}\n",
    "    filter_output = xr.DataArray(np.full(dataarray.shape[:2], np.nan), \n",
    "                                 coords=filter_coords, dims=filter_dims)\n",
    "    if filter_shape == (1,1):\n",
    "        agg_func_kwargs = dict(a=dataarray.values, axis=dataarray.get_axis_num('time'))\n",
    "        if statistic == 'mean':\n",
    "            filter_output.values[:] = np.nanmean(**agg_func_kwargs)\n",
    "        elif statistic == 'median':\n",
    "            filter_output.values[:] = np.nanmedian(**agg_func_kwargs)\n",
    "        elif statistic == 'std':\n",
    "            filter_output.values[:] = np.nanstd(**agg_func_kwargs)\n",
    "    else:\n",
    "        # Allocate a Numpy array containing the content of `dataarray`, but padded \n",
    "        # with NaNs to ensure the statistics are correct at the x and y extremeties of the data.\n",
    "        flt_shp = np.array(filter_shape)\n",
    "        del filter_shape\n",
    "        shp = np.array(dataarray.shape[:2])\n",
    "        pad_shp = (*(shp + flt_shp - 1), dataarray.shape[2])\n",
    "        padding = (flt_shp-1)//2 # The number of NaNs from an edge of the padding to the data.\n",
    "        padded_arr = np.full(pad_shp, np.nan)\n",
    "        padded_arr[padding[0]:pad_shp[0]-padding[0], \n",
    "                   padding[1]:pad_shp[1]-padding[1]] = dataarray.values\n",
    "\n",
    "        # For each point in the first two dimensions of `dataarray`...\n",
    "        for i in range(filter_output.shape[0]):\n",
    "            for j in range(filter_output.shape[1]):\n",
    "                padded_arr_segment = padded_arr[i:i+flt_shp[0],\n",
    "                                                j:j+flt_shp[1]]\n",
    "                if statistic == 'mean':\n",
    "                    filter_output.values[i,j] = np.nanmean(padded_arr_segment)\n",
    "                elif statistic == 'median':\n",
    "                    filter_output.values[i,j] = np.nanmedian(padded_arr_segment)\n",
    "                elif statistic == 'std':\n",
    "                    filter_output.values[i,j] = np.nanstd(padded_arr_segment)\n",
    "    \n",
    "    return filter_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the acquisition range by their indices and then apply statistics\n",
    "# The lower bound is inclusive. The upper bound is exclusive.\n",
    "\n",
    "# Mean VH for year 2018 (example)\n",
    "acq_ind_ranges = [(0, 23)]\n",
    "\n",
    "# The `xarray.DataArray` member of `sar_dataset` to calculate statistics for.\n",
    "stats_data_arr = 'vh'\n",
    "\n",
    "# Format `acq_ind_ranges` for xarray `isel()` and select the acquisitions.\n",
    "acq_ind_ranges = np.concatenate([np.arange(*acq_ind_range) \n",
    "                                 for acq_ind_range in acq_ind_ranges])\n",
    "stats_data = sar_dataset[stats_data_arr].isel(time=acq_ind_ranges)\\\n",
    "             .transpose('latitude', 'longitude', 'time')\n",
    "vmin, vmax = stats_data.min().values, stats_data.max().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select filter type: mean, median, std\n",
    "# Select the filter shape (odd integer, odd integer)\n",
    "\n",
    "mean_filtered_sar = stats_filter(stats_data, 'mean')\n",
    "\n",
    "figsize = figure_ratio(sar_dataset.isel(time=acq_ind_to_show), fixed_width=14)\n",
    "plt.figure(figsize=figsize)\n",
    "mean_filtered_sar.plot(cmap='Greys', vmin=-18, vmax=-15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Date Change Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select TWO acquisitions to calculate a change product\n",
    "# Choose from the indices in the table above\n",
    "\n",
    "# Compare two time slices\n",
    "\n",
    "first_acq_ind = 4\n",
    "second_acq_ind = 28\n",
    "\n",
    "\n",
    "# Select the variable to plot: vv, vh, or vvvh\n",
    "\n",
    "threshold_data_var = 'vh'\n",
    "\n",
    "# The code will calculate the difference of the two images (Second-First)\n",
    "# Define a threshold range to compare the difference of the two acquisitions\n",
    "# GREY = Pixels NOT in the threshold range \n",
    "# RED = Pixels LESS than the low end of the threshold range\n",
    "# GREEN = Pixels MORE than the high end of the threshold range\n",
    "threshold_range = (-3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert first_acq_ind >= 0 and second_acq_ind > 0, \\\n",
    "    \"The variables `first_acq_ind` and `second_acq_ind` must be positive.\"\n",
    "assert second_acq_ind > first_acq_ind, \\\n",
    "    \"The variable `second_acq_ind` must be greater than `first_acq_ind`.\"\n",
    "assert threshold_data_var in list(sar_dataset.data_vars.keys()), \\\n",
    "    \"The variable `threshold_data_var` must be one of {}.\".format(list(sar_dataset.data_vars.keys()))\n",
    "\n",
    "## Change Product Settings ##\n",
    "\n",
    "color_loss = np.array([255,0,0]) # backscatter decrease (RED)\n",
    "color_gain = np.array([0,255,0]) # backscatter increase (GREEN)\n",
    "\n",
    "# Set the size of the figure.\n",
    "figsize = figure_ratio(sar_dataset.isel(time=acq_ind_to_show), fixed_width=10)\n",
    "## End Settings ##\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "\n",
    "first_acq = sar_dataset.isel(time=first_acq_ind)\n",
    "second_acq = sar_dataset.isel(time=second_acq_ind)\n",
    "\n",
    "sar_composite = sar_dataset.median('time')\n",
    "change_product = second_acq[threshold_data_var] - first_acq[threshold_data_var]\n",
    "\n",
    "below_th = change_product.values < threshold_range[0]\n",
    "change_in_th = (threshold_range[0] < change_product.values) & \\\n",
    "               (change_product.values < threshold_range[1])\n",
    "above_th = threshold_range[1] < change_product.values\n",
    "\n",
    "rgb(sar_composite, bands=['vv_amp_8b', 'vv_amp_8b', 'vv_amp_8b'], min_possible=0, max_possible=255, \n",
    "    paint_on_mask=[(below_th, color_loss), (above_th, color_gain)], fig=fig)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_px_below = (change_product < threshold_range[0]).sum().values\n",
    "print(\"Pixels below the threshold range: {} ({:.2%})\".format( \n",
    "      num_px_below, num_px_below/change_product.size))\n",
    "num_px_in = change_in_th.sum()\n",
    "print(\"Pixels within the threshold range: {} ({:.2%})\".format(\n",
    "      num_px_in, num_px_in/change_product.size))\n",
    "num_px_above = (threshold_range[1] < change_product).sum().values\n",
    "print(\"Pixels above the threshold range: {} ({:.2%})\".format(\n",
    "      num_px_above, num_px_above/change_product.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
